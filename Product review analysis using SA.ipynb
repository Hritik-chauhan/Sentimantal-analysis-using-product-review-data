{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581de6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(\"https://www.filehippopc.online/wp-content/uploads/2021/04/sentiment-analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72fd91e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "Sentiment analysis of product reviews, an application problem, has recently become very popular in text mining and computational linguistics research. Here, we want to study the correlation between the Amazon product reviews and the rating of the products given by the customers. We use traditional machine learning algorithms including Naive Bayes analysis, Support Vector Machines and Logistic Regression. By comparing these results, we could get a better understanding of the these algorithms. They could also act as a supplement to other fraud scoring detection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8038bfc",
   "metadata": {},
   "source": [
    "# Importing packages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8058787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('1429_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39a1f8",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "Our dataset comes from **Consumer Reviews of Amazon Products**.This dataset has **34660** data points in total. Each example includes the type, name of the product as well as the text review and the rating of the product. To better utilize the data, first we extract the rating and review column since these two are the essential part of this project.Then, we found that there are some data points which has no ratings when we went through the data. After eliminating those examples, we have **34627** data points in **total**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data points before elimination : \",len(df))\n",
    "df=df.dropna(subset=[\"reviews.rating\"])\n",
    "print(\"Data points after elimination : \",len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c038dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52d49",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "To have a brief overview of the dataset, we have plot the distribution of the ratings.it shows that we have 5 classes - rating 1 to 5 as well as the distribution among them. Also, these five classes are actually imbalanced as class 1 and class 2 have small amount of data while class 5 has more than 20000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='reviews.rating', data=df)\n",
    "\n",
    "plt.title('Distribution of rating scores')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6fb89",
   "metadata": {},
   "source": [
    "### Due to the high imbalance of our dataset, we find and added more datapoints with low ratings from other resources.\n",
    "We think this might help us solve the problem of data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the other dataset\n",
    "df2 = pd.read_csv(\"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "df3 = pd.read_csv(\"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "\n",
    "# Eliminating data points which has no ratings\n",
    "df2=df2.dropna(subset=[\"reviews.rating\"])\n",
    "df3=df3.dropna(subset=[\"reviews.rating\"])\n",
    "\n",
    "# using only data of rating lower than or equal to 3 and resetting index after filtering rows\n",
    "df2 = df2[df2[\"reviews.rating\"] <= 3].reset_index(drop=True) \n",
    "df3 = df3[df3[\"reviews.rating\"] <= 3].reset_index(drop=True)\n",
    "df2['reviews.rating'].value_counts().sort_index(ascending=False)\n",
    "df3['reviews.rating'].value_counts().sort_index(ascending=False)\n",
    "\n",
    "# concatenation\n",
    "data = pd.concat([df, df2, df3])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee391465",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='reviews.rating', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe799",
   "metadata": {},
   "source": [
    "Based on the descriptive statistics above, we see the following:\n",
    "\n",
    "* Average review score has decreased to 4.38, with low standard deviation\n",
    "* Most review are positive from 2nd quartile onwards\n",
    "* The average for number of reviews helpful (reviews.numHelpful) is 0.65 but high standard deviation\n",
    "* The data are pretty spread out around the mean, and since can't have negative people finding something helpful, then this is only on the right tail side\n",
    "* The range of most reviews will be between 0-13 people finding helpful (reviews.numHelpful)\n",
    "* The most helpful review was helpful to 814 people\n",
    "* This could be a detailed, rich review that will be worth looking a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43ddea",
   "metadata": {},
   "source": [
    "Based on the information above:\n",
    "\n",
    "* Drop reviews.userCity, reviews.userProvince, reviews.id, and reviews.didPurchase since these values are floats (for exploratory analysis only)\n",
    "* Not every category have maximum number of values in comparison to total number of values\n",
    "* reviews.text category has minimum missing data (37727/37728) -> Good news!\n",
    "* We need to clean up the name column by referencing asins (unique products) since we have 7000 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"asins\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asins_unique = len(data[\"asins\"].unique())\n",
    "print(\"Number of Unique ASINs: \" + str(asins_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ace80",
   "metadata": {},
   "source": [
    "Next, we will explore the following columns:\n",
    "\n",
    "* asins\n",
    "* reviews.rating\n",
    "* (reviews.numHelpful - not possible since numHelpful is only between 0-13 as per previous analysis in Raw Data)\n",
    "* (reviews.text - not possible since text is in long words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076cbf2",
   "metadata": {},
   "source": [
    "# reviews.rating / ASINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "asins_count_ix = data[\"asins\"].value_counts().index\n",
    "plt.subplots(2,1,figsize=(16,12))\n",
    "plt.subplot(2,1,1)\n",
    "data[\"asins\"].value_counts().plot(kind=\"bar\", title=\"ASIN Frequency\",color=['yellow', 'red', 'blue'])\n",
    "plt.subplot(2,1,2)\n",
    "sns.pointplot(x=\"asins\", y=\"reviews.rating\", order=asins_count_ix, data=data )\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9061d34e",
   "metadata": {},
   "source": [
    "* 1a) The most frequently reviewed products have their average review ratings in the 4.5 - 4.8 range, with little variance\n",
    "* 1b) Although there is a slight inverse relationship between the ASINs frequency level and average review ratings for the first 4 ASINs, this relationship is not significant since the average review for the first 4 ASINs are rated between 4.5 - 4.8, which is considered good overall reviews\n",
    "* 2a) For ASINs with lower frequencies as shown on the bar graph (top), we see that their corresponding average review ratings on the point-plot graph (bottom) has significantly higher variance as shown by the length of the vertical lines. As a result, we suggest that, the average review ratings for ASINs with lower frequencies are not significant for our analysis due to high variance\n",
    "* 2b) On the other hand, due to their lower frequencies for ASINs with lower frequencies, we suggest that this is a result of lower quality products\n",
    "* 2c) Furthermore, the last 4 ASINs have no variance due to their significantly lower frequencies, and although the review ratings are a perfect 5.0, but we should not consider the significance of these review ratings due to lower frequency as explained in 2a)\n",
    "\n",
    "**Note that point-plot graph automatically takes the average of the review.rating data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9aae42",
   "metadata": {},
   "source": [
    "# Analysis \n",
    "Using the features in place, we will build a classifier that can determine a review's sentiment.\n",
    "\n",
    "## Set Target Variable (Sentiments)\n",
    "Segregate ratings from 1-5 into positive, neutral, and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiments(rating):\n",
    "    if (rating == 5) or (rating == 4):\n",
    "        return \"Positive\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    elif (rating == 2) or (rating == 1):\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2aa2d",
   "metadata": {},
   "source": [
    "# Splitting Dataset into Train and Test Set\n",
    "* Before we explore the dataset we're going to split it into training set and test sets\n",
    "* Our goal is to eventually train a sentiment analysis classifier\n",
    "* Since the majority of reviews are positive (5 stars), we will need to do a stratified split on the reviews score to ensure that we don't train the classifier on imbalanced data\n",
    "* To use sklearn's **train_test_split** class, we're going to convert all review rating to **integer** datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "data[\"reviews.rating\"] = data[\"reviews.rating\"].astype(int)\n",
    "data[\"Sentiment\"] = data[\"reviews.rating\"].apply(sentiments)\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "    data[\"reviews.text\"], data[\"Sentiment\"] , test_size=0.20, random_state=42, stratify= data[\"reviews.rating\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30440c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Sample :\",len(X_train))\n",
    "print(\"Testing sample :\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb93518",
   "metadata": {},
   "source": [
    "# Feature Engineering and Selection\n",
    "Here we will turn content into numerical feature vectors using the  **Bag of Words** strategy:\n",
    "\n",
    "* **Assign fixed integer id to each word occurrence (integer indices to word occurrence dictionary)**\n",
    "* **X[i,j] where i is the integer indices, j is the word occurrence, and X is an array of words (our training set)**\n",
    "\n",
    "\n",
    "In order to implement the **Bag of Words** strategy, we will use SciKit-Learn's **CountVectorizer** to performs the following:\n",
    "\n",
    "* Text preprocessing:\n",
    "* Tokenization (breaking sentences into words)\n",
    "* Stopwords (filtering \"the\", \"are\", etc)\n",
    "* Occurrence counting (builds a dictionary of features from integer indices with word occurrences)\n",
    "* Feature Vector (converts the dictionary of text documents into a feature vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"nan\" with space\n",
    "X_train = X_train.fillna(' ')\n",
    "X_test = X_test.fillna(' ')\n",
    "y_train = y_train.fillna(' ')\n",
    "y_test = y_test.fillna(' ')\n",
    "\n",
    "# Text preprocessing and occurance counting\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train) \n",
    "X_train_counts.shape\n",
    "print(\"Training Sample :\",(X_train_counts.shape[0]))\n",
    "print(\"Distinct Words :\", (X_train_counts.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad997047",
   "metadata": {},
   "source": [
    "With longer documents, we typically see higher average count values on words that carry very little meaning, this will overshadow shorter documents that have lower average counts with same frequencies, as a result, we will use **TfidfTransformer** to reduce this redundancy:\n",
    "\n",
    "* **Term Frequencies (Tf) divides number of occurrences for each word by total number of words**\n",
    "* **Term Frequencies times Inverse Document Frequency (Tfidf) downscales the weights of each word (assigns less value to unimportant stop words ie. \"the\", \"are\", etc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ce9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_nominalNB\", MultinomialNB())])\n",
    "clf_multiNB_pipe.fit(X_train, y_train)\n",
    "predictedMultiNB = clf_multiNB_pipe.predict(X_test)\n",
    "np.mean(predictedMultiNB == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf_logReg_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_logReg\", LogisticRegression())])\n",
    "clf_logReg_pipe.fit(X_train, y_train)\n",
    "\n",
    "predictedLogReg = clf_logReg_pipe.predict(X_test)\n",
    "np.mean(predictedLogReg == y_test)\n",
    "print('Accuracy: {}'. format(accuracy_score(y_test, predictedLogReg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linearSVC_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_linearSVC\", LinearSVC())])\n",
    "clf_linearSVC_pipe.fit(X_train, y_train)\n",
    "\n",
    "predictedLinearSVC = clf_linearSVC_pipe.predict(X_test)\n",
    "np.mean(predictedLinearSVC == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(classification_report(y_test,predictedLinearSVC))\n",
    "print('Accuracy: {}'. format(accuracy_score(y_test, predictedLinearSVC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test, predictedLinearSVC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
